{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsungchi-source/HW/blob/main/1022_week7_%E5%A4%9A%E6%A8%A1%E6%85%8B_Multimodal__%E8%9E%8D%E5%90%88%E6%96%B9%E5%BC%8F%E7%82%BAearly_%E5%8A%89%E5%AE%97%E6%97%97.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gdown可以下載存放在Google雲端的檔案，類似wget\n",
        "\n",
        "gdown github: https://github.com/wkentaro/gdown"
      ],
      "metadata": {
        "id": "TBnUmneUvZVh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lTdghIjSwUb"
      },
      "outputs": [],
      "source": [
        "!pip install ipywidgets --upgrade\n",
        "# 使用gdown下載資料\n",
        "!gdown 1bZREL8xxNX4Us5vYtgsg6TomMTdaUARC # Reddit新聞資料\n",
        "!gdown 1PLO60_bOaIYKzyoGyZHqUMv7WckvJBEw # 道瓊股價資料"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "Kz2mC2lwxYQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "L_T49VuIxYQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "sV__5CEExYQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 資料集\n",
        "* 文本資料：每日reddit新聞標題 - 代表市場情緒和輿論\n",
        "* 股價資料：道瓊工業平均指數 - 代表市場實際表現\n",
        "\n",
        "# 為什麼選擇這兩種資料？\n",
        "1. 異質性：文本(非結構化) vs 數值(結構化) - 測試融合策略的效果\n",
        "2. 時間序列性：都具有時間依賴性，適合LSTM處理\n",
        "3. 相關性：新聞情緒理論上會影響股價，有內在關聯\n",
        "\n",
        "\n",
        "資料集來源：https://www.kaggle.com/competitions/stock-market-prediction-and-sentimental-analysis/data"
      ],
      "metadata": {
        "id": "Gd1r4o2UwNpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型融合的各種型態\n",
        "![多模態融合的各種形式](https://www.researchgate.net/publication/362028535/figure/fig2/AS:11431281126156761@1678559245845/llustration-of-early-fusion-late-fusion-and-middle-fusion-methods-used-by-multimodal.jpg)\n",
        "\n",
        "本次作業主要實作的內容是(c)中期融合（Middle Fusion）"
      ],
      "metadata": {
        "id": "bfwkO4xmN60n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8osuZFudMae"
      },
      "source": [
        "# 文本資料處理\n",
        "\n",
        "## 目標：將新聞文本轉換為數值向量\n",
        "新聞文本無法直接輸入機器學習模型，需要先轉換為數值表示\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import time"
      ],
      "metadata": {
        "id": "NMZSv9IdGBUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvJdgHB2YMlY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 讀取新聞資料\n",
        "news_df = pd.read_csv('RedditNews(train).csv', encoding='utf-8')\n",
        "# 資料清理：移除字串前後的 b'...' 標記\n",
        "# 原因：原始資料中有些文本被存成 b'content' 格式，需要清理\n",
        "# regex解釋：\n",
        "#   ^b     - 匹配字串開頭的 'b'\n",
        "#   ['\\\"]  - 匹配單引號或雙引號\n",
        "#   |      - 或者\n",
        "#   ['\\\"]$ - 匹配字串結尾的單引號或雙引號\n",
        "news_df['News'] = news_df['News'].str.replace(r\"^b['\\\"]|['\\\"]$\", '', regex=True)\n",
        "# 印出錢10筆資料\n",
        "news_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL4r_2pR5MDM"
      },
      "outputs": [],
      "source": [
        "# 查看每日新聞數量\n",
        "date_counts = news_df['Date'].value_counts().reset_index()\n",
        "# 根據日期排序\n",
        "date_counts.sort_values(by='Date', ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wH8IsdScezMX"
      },
      "outputs": [],
      "source": [
        "# 將每日新聞標題合併成一則新聞\n",
        "# 目標：將同一天的多則新聞合併成單一文本\n",
        "# 原因：模型需要每天一個輸入，而不是每天多個分散的新聞\n",
        "news_dict = news_df.groupby('Date')['News'].apply(list).to_dict()\n",
        "news_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6m9vACCpQyw"
      },
      "outputs": [],
      "source": [
        "# 下載 Hugging Face Transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkmshLH_qDdT"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\"\"\"BERT文本編碼\n",
        "\n",
        "為什麼使用BERT？\n",
        "1. **語義理解**：BERT能理解詞語在上下文中的含義\n",
        "2. **預訓練優勢**：已在大量文本上訓練，具備豐富語言知識\n",
        "3. **向量化**：將文本轉換為768維的密集向量表示\n",
        "\n",
        "技術細節\n",
        "- 使用[CLS] token作為整體文本表示\n",
        "- 每個新聞日期產生一個768維向量\n",
        "- 這個向量包含了該日所有新聞的語義資訊\n",
        "\"\"\"\n",
        "\n",
        "# 初始化BERT模型和分詞器\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# 設置為評估模式（關閉dropout等訓練相關功能）\n",
        "# 原因：我們只用BERT做特徵提取，不進行訓練\n",
        "bert_model.eval()\n",
        "print('載入 BERT 成功')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMW4jifKq9Bc"
      },
      "outputs": [],
      "source": [
        "# 設置設備（CPU/GPU/MPS）偵測使用什麼設備\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "# 將模型移動到訓練設備\n",
        "bert_model.to(device)\n",
        "print(f'模型目前使用{device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtV5eR0zsU2O"
      },
      "outputs": [],
      "source": [
        "\"\"\"#批次文本編碼處理\n",
        "\n",
        "逐日處理新聞文本，將每天的所有新聞合併後輸入BERT\n",
        "\"\"\"\n",
        "date_embeddings = {} # 儲存每日的文本嵌入向量\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 逐日期處理\n",
        "for date, news_list in news_dict.items():\n",
        "\n",
        "    # 步驟1合併當天的所有新聞為一個文本（用空格分隔）\n",
        "    # 原因：需要將一天內的多則新聞統合成單一語義表示\n",
        "    combined_text = \" \".join(news_list)\n",
        "    # 步驟2：文本預處理和分詞\n",
        "    # 將文本 Tokenize 並輸入到 BERT\n",
        "    # max_length=512：BERT的最大輸入長度限制\n",
        "    # truncation=True：如果超過長度就截斷\n",
        "    inputs = tokenizer(combined_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    outputs = bert_model(**inputs)\n",
        "    print(f'{date} done.')\n",
        "\n",
        "    # 提取[CLS] token的嵌入（位置0）作為整體文本表示\n",
        "    # [CLS] token設計用來代表整個句子的語義\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "    # 儲存該日期的語義向量\n",
        "    date_embeddings[date] = cls_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmBk2KLwRR3Q"
      },
      "outputs": [],
      "source": [
        "# 將嵌入字典轉換為DataFrame格式，方便後續處理\n",
        "embedding_df = pd.DataFrame(date_embeddings).T  # 轉置：日期為行，特徵為列\n",
        "embedding_df.columns = [f\"Embedding_{i}\" for i in range(embedding_df.shape[1])] # 重新命名列\n",
        "embedding_df['Date'] = embedding_df.index\n",
        "embedding_df['Date'] = pd.to_datetime(embedding_df['Date'], format='%Y-%m-%d') # 日期格式化\n",
        "# 印出前10筆資料\n",
        "embedding_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KTKQnzcu_YX"
      },
      "source": [
        "# 股價資料處理\n",
        "\n",
        "# 目標：準備時間序列數值特徵\n",
        "股價資料包含開盤價、收盤價、最高價、最低價、成交量等\n",
        "我們主要使用收盤價作為預測目標的基準\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80Cj8eWnR73C"
      },
      "outputs": [],
      "source": [
        "# 讀取股價資料\n",
        "stock_data = pd.read_csv('DJIA_table(train).csv', encoding='utf-8')\n",
        "# 日期欄位轉換成 datetime 格式\n",
        "stock_data['Date'] = pd.to_datetime(stock_data['Date'], dayfirst=True)\n",
        "# 設定日期為索引\n",
        "stock_data.set_index('Date', inplace=True)\n",
        "# 根據日期排序\n",
        "stock_data = stock_data.sort_index()\n",
        "# 印出前10筆\n",
        "stock_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlNIE05Tu_YX"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "多模態資料合併\n",
        "目標：將文本特徵和數值特徵按日期對齊\n",
        "這是多模態學習的關鍵步驟：確保不同模態的資料在時間維度上對應\n",
        "\"\"\"\n",
        "\n",
        "# 只保留收盤價\n",
        "price_df = stock_data[['Close']]\n",
        "# 根據日期合併收盤價和嵌入\n",
        "combined_df = pd.merge(price_df, embedding_df, on='Date')\n",
        "# 設定日期為索引\n",
        "combined_df.set_index('Date', inplace=True)\n",
        "# 根據日期排序\n",
        "combined_df = combined_df.sort_index()\n",
        "# 印出前10筆\n",
        "combined_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 資料標記、滑動窗口\n",
        "\n",
        "# 目標：創建預測標籤和時間序列窗口\n",
        "1. **技術指標**：使用移動平均線判斷趨勢\n",
        "2. **標籤策略**：短期均線>長期均線 = 多頭(1)，否則為空頭(0)\n",
        "3. **滑動窗口**：將連續N天的資料作為一個訓練樣本\n",
        "\n",
        "# 為什麼用移動平均交叉？\n",
        "- **降噪**：平滑價格波動，減少雜訊\n",
        "- **趨勢識別**：短長期均線交叉是經典的技術分析信號\n",
        "- **實用性**：在實際交易中廣泛使用的策略\n",
        "\n"
      ],
      "metadata": {
        "id": "32m17c9zxImS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF7fFVDZu_YY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 加入均線（後續標記漲跌用）\n",
        "def add_MA(df, short_window=5, long_window=20):\n",
        "    \"\"\"\n",
        "    添加移動平均線技術指標\n",
        "\n",
        "    參數:\n",
        "        df: 包含價格資料的DataFrame\n",
        "        short_window: 短期移動平均窗口（預設5天）\n",
        "        long_window: 長期移動平均窗口（預設20天）\n",
        "\n",
        "    原理:\n",
        "        - 短期均線反應近期價格變化\n",
        "        - 長期均線反映整體趨勢\n",
        "        - 兩者交叉點常被視為趨勢轉換信號\n",
        "    \"\"\"\n",
        "    df['MA_short'] = df['Close'].rolling(window=short_window).mean()\n",
        "    df['MA_long'] = df['Close'].rolling(window=long_window).mean()\n",
        "    return df\n",
        "\n",
        "# 標記漲跌\n",
        "def create_labels(df):\n",
        "    \"\"\"\n",
        "    根據移動平均線交叉創建分類標籤\n",
        "\n",
        "    標籤邏輯:\n",
        "        1 (多頭): 短期均線 > 長期均線，預期上漲\n",
        "        0 (空頭): 短期均線 ≤ 長期均線，預期下跌\n",
        "\n",
        "    這種標籤策略的優點:\n",
        "        - 基於技術分析理論\n",
        "        - 自動識別趨勢方向\n",
        "        - 適合機器學習的二分類任務\n",
        "    \"\"\"\n",
        "    # 計算移動平均線\n",
        "    df = add_MA(df.copy())\n",
        "\n",
        "    # 標記漲跌：短期均線在長期均線上方為1（多頭），下方為0（空頭）\n",
        "    df['Target'] = (df['MA_short'] > df['MA_long']).astype(int)\n",
        "\n",
        "    # 移除包含 NaN 的行（因為計算均線導致的）\n",
        "    df = df.dropna()\n",
        "\n",
        "    print(\"多頭信號（1）數量:\", sum(df['Target'] == 1))\n",
        "    print(\"空頭信號（0）數量:\", sum(df['Target'] == 0))\n",
        "\n",
        "    return df\n",
        "\n",
        "# 準備序列資料\n",
        "def prepare_sequence_data(df, sequence_length=5):\n",
        "    \"\"\"\n",
        "    準備時間序列滑動窗口資料\n",
        "\n",
        "    參數:\n",
        "        df: 包含特徵和標籤的DataFrame\n",
        "        sequence_length: 滑動窗口長度（預設5天）\n",
        "\n",
        "    滑動窗口原理:\n",
        "        - 使用過去N天的資料預測第N+1天\n",
        "        - 例如：用第1-5天的資料預測第6天\n",
        "        - 這樣可以讓模型學習時間序列的模式\n",
        "\n",
        "    輸出:\n",
        "        X_price: 價格時間序列 [樣本數, 時間步, 價格特徵數]\n",
        "        X_news: 新聞時間序列 [樣本數, 時間步, 新聞特徵數]\n",
        "        y: 對應的標籤 [樣本數]\n",
        "    \"\"\"\n",
        "    # 分離特徵\n",
        "    price_cols = ['Close', 'MA_short', 'MA_long']  # 價格相關特徵，現在包含均線\n",
        "    news_cols = [col for col in df.columns if col.startswith('Embedding_')] # 新聞嵌入特徵\n",
        "\n",
        "    X_price, X_news, y = [], [], []\n",
        "\n",
        "    for i in range(len(df) - sequence_length):\n",
        "        # 提取時間窗口內的價格序列\n",
        "        # 價格序列（包含均線）\n",
        "        price_seq = df[price_cols].iloc[i:i+sequence_length].values\n",
        "        X_price.append(price_seq) # 添加至清單中\n",
        "        # 提取時間窗口內的新聞序列\n",
        "        # 新聞序列\n",
        "        news_seq = df[news_cols].iloc[i:i+sequence_length].values\n",
        "        X_news.append(news_seq) # 添加至清單中\n",
        "        # 提取預測目標（窗口後一天的標籤）\n",
        "        # 目標值\n",
        "        y.append(df['Target'].iloc[i+sequence_length]) # 添加至清單中\n",
        "\n",
        "    return np.array(X_price), np.array(X_news), np.array(y)\n",
        "\n",
        "'''函數呼叫'''\n",
        "# 加入均線\n",
        "combined_df = add_MA(combined_df)\n",
        "\n",
        "# 使用均線標記漲跌\n",
        "combined_df = create_labels(combined_df)\n",
        "\n",
        "# 創建序列資料\n",
        "X_price, X_news, y = prepare_sequence_data(combined_df, sequence_length=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec1s-vBru_YY"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "資料分割與標準化\n",
        "\n",
        "目標：準備訓練和測試集\n",
        "  1. 時間分割：按時間順序分割，避免未來資訊洩漏\n",
        "  2. 標準化：統一特徵尺度，提升模型訓練效果\n",
        "\"\"\"\n",
        "# 切分訓練集和測試集(80%訓練，20%測試)\n",
        "# 重要：按時間順序分割，不隨機打亂（避免時間洩漏）\n",
        "split_index = int(len(X_price) * 0.8)\n",
        "\n",
        "# 股價序列\n",
        "X_price_train = X_price[:split_index]\n",
        "X_price_test = X_price[split_index:]\n",
        "\n",
        "# 新聞序列\n",
        "X_news_train = X_news[:split_index]\n",
        "X_news_test = X_news[split_index:]\n",
        "\n",
        "# 目標值（0:跌, 1:漲）\n",
        "y_train = y[:split_index]\n",
        "y_test = y[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eWfN9mku_YY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 標準化收盤價\n",
        "price_scaler = MinMaxScaler()\n",
        "X_price_train_scaled = price_scaler.fit_transform(X_price_train.reshape(-1, 1)).reshape(X_price_train.shape)\n",
        "X_price_test_scaled = price_scaler.transform(X_price_test.reshape(-1, 1)).reshape(X_price_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF8UUzyLu_YY"
      },
      "outputs": [],
      "source": [
        "# 顯示訓練資料集和測試資料集的大小 (資料筆數, 特徵數)\n",
        "print('訓練集形狀：', X_price_train_scaled.shape, X_news_train.shape, y_train.shape)\n",
        "print('測試集形狀：', X_price_test_scaled.shape, X_news_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建立模型-多模態融合模型建構\n",
        "\n",
        "## 核心概念：不同的融合時機\n",
        "\n",
        "### 1. **Early Fusion (早期融合)**\n",
        "- **融合點**：輸入層\n",
        "- **特點**：直接串接原始特徵\n",
        "- **優勢**：結構簡單，計算效率高\n",
        "- **劣勢**：可能造成特徵混雜，難以發揮各模態優勢\n",
        "\n",
        "### 2. **Middle Fusion (中期融合)**\n",
        "- **融合點**：特徵層\n",
        "- **特點**：各模態先獨立處理，再融合特徵\n",
        "- **優勢**：平衡獨立性與交互性\n",
        "- **劣勢**：需要設計融合點\n",
        "\n",
        "### 3. **Late Fusion (晚期融合)**\n",
        "- **融合點**：決策層\n",
        "- **特點**：各模態完全獨立預測，最後合併決策\n",
        "- **優勢**：保持模態獨立性，可解釋性強\n",
        "- **劣勢**：可能錯失深層交互機會"
      ],
      "metadata": {
        "id": "EaFcS_MZxGen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqL9Exxru_YZ"
      },
      "outputs": [],
      "source": [
        "\"\"\" 建立模型\n",
        "\n",
        "## 作業重點：\n",
        "**只需要修改下面的 fusion_type 參數，嘗試不同的融合方式！**\n",
        "\n",
        "### 選擇融合方式：\n",
        "- `fusion_type = \"early\"`   # 早期融合\n",
        "- `fusion_type = \"middle\"`  # 中期融合 (base)\n",
        "- `fusion_type = \"late\"`    # 晚期融合\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf # 引入tensorflow框架\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,  # 輸入層\n",
        "    LSTM, # 長短期記憶\n",
        "    Dense, # 全鏈接層\n",
        "    Concatenate, # 合併層，這邊用來合併文本與數值特徵\n",
        "    TimeDistributed, # 為了讓降維時不影響時間維度（窗口）\n",
        "    Flatten, # 展平層\n",
        "    Average, # 平均層\n",
        "    Dropout # 隨機失活 - 防止過擬合\n",
        ")\n",
        "\n",
        "def build_multimodal_model(sequence_length, fusion_type=\"early\"):\n",
        "    \"\"\"\n",
        "    建立多模態融合模型\n",
        "\n",
        "    參數:\n",
        "        sequence_length: 時間序列長度（預設5天）\n",
        "        fusion_type: 融合策略 (\"early\", \"middle\", \"late\")\n",
        "\n",
        "    只需要修改fusion_type參數，就能體驗不同融合方式的效果\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"建立 {fusion_type.upper()} 融合模型...\")\n",
        "\n",
        "    # 輸入層定義（三種方式都相同）\n",
        "    # price_input: [batch_size, sequence_length, 3] - 3個價格特徵\n",
        "    price_input = Input(shape=(sequence_length, 3), name='price_input')\n",
        "    # news_input: [batch_size, sequence_length, 768]\n",
        "    news_input = Input(shape=(sequence_length, 768), name='news_input')\n",
        "\n",
        "    if fusion_type == \"early\":\n",
        "        # ========== 早期融合：輸入層直接合併 ==========\n",
        "        print(\"早期融合：在輸入層直接串接特徵\")\n",
        "\n",
        "        # 步驟1：新聞特徵降維（避免維度不平衡）\n",
        "        # 原因：新聞768維 vs 價格3維，維度差異太大，需要平衡\n",
        "        # TimeDistributed：確保降維操作在每個時間步都執行\n",
        "        news_reduced = TimeDistributed(Dense(32, activation='relu'),\n",
        "                                     name='news_dim_reduction')(news_input)\n",
        "\n",
        "        # 步驟2：特徵直接串接\n",
        "        # 將價格[batch, 5, 3]和降維新聞[batch, 5, 32]串接成[batch, 5, 35]\n",
        "        fused_features = Concatenate(axis=-1, name='early_fusion')([price_input, news_reduced])\n",
        "\n",
        "        # 步驟3：統一LSTM處理混合特徵\n",
        "        # 使用較大的LSTM(64)來處理複雜的混合特徵\n",
        "        lstm_out = LSTM(64, name='unified_lstm')(fused_features)\n",
        "        lstm_out = Dropout(0.2)(lstm_out)\n",
        "        dense = Dense(32, activation='relu', name='dense_layer')(lstm_out)\n",
        "        output = Dense(1, activation='sigmoid', name='output_layer')(dense)\n",
        "\n",
        "    elif fusion_type == \"middle\":\n",
        "        # ========== 中期融合：特徵層合併 ==========\n",
        "        print(\"中期融合：分別處理後在特徵層合併\")\n",
        "\n",
        "        # 價格處理分支\n",
        "        # 直接用LSTM處理價格時間序列，學習價格模式\n",
        "        price_lstm = LSTM(32, name='price_lstm')(price_input)\n",
        "\n",
        "        # 新聞處理分支\n",
        "        # 先降維再用LSTM，學習新聞語義的時間演化\n",
        "        news_dense = TimeDistributed(Dense(32), name='news_dense')(news_input)\n",
        "        news_lstm = LSTM(16, name='news_lstm')(news_dense)\n",
        "\n",
        "        # 中期融合點：在特徵表示層合併\n",
        "        # 此時各模態已經學習到專門的特徵表示\n",
        "        merged = Concatenate(name='middle_fusion')([price_lstm, news_lstm])\n",
        "        # 最終決策層\n",
        "        dense = Dense(32, activation='linear', name='dense_layer')(merged)\n",
        "        output = Dense(1, activation='sigmoid', name='output_layer')(dense)\n",
        "\n",
        "    elif fusion_type == \"late\":\n",
        "        # ========== 晚期融合：決策層合併 ==========\n",
        "        print(\"晚期融合：各自預測後合併結果\")\n",
        "\n",
        "        # 價格預測分支（完全獨立）\n",
        "        price_lstm = LSTM(32, name='price_lstm')(price_input)\n",
        "        price_dense = Dense(16, activation='relu', name='price_dense')(price_lstm)\n",
        "        # 獨立的價格預測結果\n",
        "        price_prediction = Dense(1, activation='sigmoid', name='price_prediction')(price_dense)\n",
        "\n",
        "        # 新聞預測分支（完全獨立）\n",
        "        news_dense = TimeDistributed(Dense(32), name='news_dense')(news_input)\n",
        "        news_lstm = LSTM(16, name='news_lstm')(news_dense)\n",
        "        news_dense2 = Dense(16, activation='relu', name='news_dense2')(news_lstm)\n",
        "        # 獨立的新聞預測結果\n",
        "        news_prediction = Dense(1, activation='sigmoid', name='news_prediction')(news_dense2)\n",
        "\n",
        "        # 晚期融合點：合併兩個預測結果\n",
        "        # 不是簡單平均，而是學習最佳組合權重\n",
        "        predictions_concat = Concatenate(name='predictions_concat')([price_prediction, news_prediction])\n",
        "        fusion_dense = Dense(8, activation='relu', name='fusion_dense')(predictions_concat)\n",
        "        output = Dense(1, activation='sigmoid', name='output_layer')(fusion_dense)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"fusion_type 必須是 'early', 'middle', 或 'late'\")\n",
        "\n",
        "    # 建立模型\n",
        "    model = Model(inputs=[price_input, news_input], outputs=output,\n",
        "                  name=f'{fusion_type}_fusion_model')\n",
        "\n",
        "    # 編譯模型\n",
        "    model.compile(optimizer='adam', # Adam優化器：自適應學習率，適合大多數任務\n",
        "                 loss='binary_crossentropy', # 二元交叉熵：適合二分類任務\n",
        "                 metrics=['accuracy']) # 評估指標：準確率\n",
        "\n",
        "    print(f\"{fusion_type.upper()} 融合模型建立完成！\")\n",
        "    print(f\"總參數量: {model.count_params():,}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B8lOeARu_YZ"
      },
      "outputs": [],
      "source": [
        "# 作業：修改這裡的 fusion_type 參數！\n",
        "# ============================================\n",
        "fusion_type = \"early\"  # ← 在這裡修改：early, middle, late\n",
        "# ============================================\n",
        "\n",
        "multimodal = build_multimodal_model(sequence_length=5, fusion_type=fusion_type)\n",
        "multimodal.summary()\n",
        "\n",
        "plot_model(\n",
        "  multimodal, # 模型\n",
        "  to_file=f'./{fusion_type}_fusion_model.png', # 可視化圖儲存路徑\n",
        "  show_shapes=False,  # 顯示維度\n",
        "  show_layer_names=True, # 顯示模型名稱\n",
        "  dpi=120 # 解析度\n",
        "  )\n",
        "\n",
        "# 顯示圖片（在 Colab 中）\n",
        "from IPython.display import Image, display\n",
        "print(f\"{fusion_type.upper()} 融合模型架構圖：\")\n",
        "display(Image(f'./{fusion_type}_fusion_model.png'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"## 訓練模型\"\"\"\n",
        "\n",
        "print(f\"開始訓練 {fusion_type.upper()} 融合模型...\")\n",
        "start_time = time.time()\n",
        "\n",
        "history = multimodal.fit(\n",
        "    [X_price_train_scaled, X_news_train], # X (股價, 新聞)，順序需對應模型定義時的結構\n",
        "    y_train, # y (漲或跌)\n",
        "    validation_split=0.2,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"訓練時間: {training_time:.1f} 秒\")"
      ],
      "metadata": {
        "id": "kD0u7ZG637E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 結果評估"
      ],
      "metadata": {
        "id": "Cz3czlljxPjO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZc1R44eu_YZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"# 結果評估\"\"\"\n",
        "\n",
        "# 測試集評估\n",
        "loss, accuracy = multimodal.evaluate([X_price_test_scaled, X_news_test], y_test, verbose=0)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"{fusion_type.upper()} 融合模型評估結果\")\n",
        "print(\"=\"*50)\n",
        "print(f\"測試準確率: {accuracy:.4f}\")\n",
        "print(f\"參數量: {multimodal.count_params():,}\")\n",
        "print(f\"訓練時間: {training_time:.1f} 秒\")\n",
        "print(\"=\"*50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "finance",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}